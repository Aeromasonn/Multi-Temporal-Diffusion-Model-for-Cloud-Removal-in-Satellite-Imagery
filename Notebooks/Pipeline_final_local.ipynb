{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os, sys\n",
    "repo_root = os.path.abspath(\"..\")\n",
    "if repo_root not in sys.path:\n",
    "    sys.path.append(repo_root)\n",
    "    \n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "import Model.Dataloader as Dataloader\n",
    "from Model.Dataloader import prep_data_local\n",
    "import Model.model as model\n",
    "import Model.utils as utils\n",
    "from Model.model import build_forward_model, backward_sampler\n",
    "import Model.trainers as trainers\n",
    "from Model.trainers import forward_trainer\n",
    "from Model.utils import visualize"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load Full Sen2_MTC data locally",
   "id": "c8d0bfb44eaeeaec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "path = \"../Sen2_MTC/dataset/Sen2_MTC\"\n",
    "patch_size = 128\n",
    "stride = 128\n",
    "batch_size = 16\n",
    "train_ratio = .7\n",
    "val_ratio = .15\n",
    "\n",
    "train_loader, val_loader, test_loader = prep_data_local(path=path, \n",
    "                                                        patch_size=patch_size, \n",
    "                                                        stride=stride,\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        train_ratio=train_ratio,\n",
    "                                                        val_ratio=val_ratio)\n",
    "#expect ~40s run on full Sen2_MTC data"
   ],
   "id": "69627c82585c67c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    print(batch['cloudy_seq'].shape)\n",
    "    print(batch['clean'].shape)\n",
    "    x = batch['cloudy_seq'][0]\n",
    "    print(x.mean(), x.std())\n",
    "    break"
   ],
   "id": "d5d7092f0b52e5d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Build and Train the model",
   "id": "36827b3ed6648bbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_dict = build_forward_model(\n",
    "    in_channels = 4,\n",
    "    base_channels = 32,\n",
    "    num_stages = 2,\n",
    "    latent_dim = 128,\n",
    "    T_cloud=3,\n",
    "    T_diffusion=750,\n",
    "    device=device\n",
    ")\n",
    "base_encoder = model_dict['base_encoder']\n",
    "cloud_encoder = model_dict['cloud_encoder']\n",
    "forwarder = model_dict['forwarder']\n",
    "denoiser = model_dict['denoiser']\n",
    "\n",
    "cloud_enc_count = utils.count_params(cloud_encoder)\n",
    "forward_enc_count = utils.count_params(forwarder)\n",
    "denoiser_count = utils.count_params(denoiser)\n",
    "print(f\"Total number of parameters: {cloud_enc_count+forward_enc_count+denoiser_count}\")"
   ],
   "id": "a1d04055122d9925",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "epochs = 5\n",
    "params = list(cloud_encoder.parameters()) + list(denoiser.parameters())\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        {\"params\": denoiser.parameters(),      \"lr\": 1e-4},\n",
    "        {\"params\": cloud_encoder.parameters(), \"lr\": 5e-5},\n",
    "    ],\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "forward_trainer(epochs=epochs,\n",
    "                train_loader=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                forwarder=forwarder,\n",
    "                cloud_encoder=cloud_encoder,\n",
    "                denoiser=denoiser,\n",
    "                device=device)"
   ],
   "id": "1d46f6f8cd393fca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Backward sampling & View training results",
   "id": "1464a51930b65862"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cloud_encoder.eval()\n",
    "denoiser.eval()\n",
    "batch = next(iter(train_loader))\n",
    "cloudy_seq = batch['cloudy_seq'].to(device)\n",
    "\n",
    "x0 = backward_sampler(cloudy_seq=cloudy_seq,\n",
    "                      cloud_encoder=cloud_encoder,\n",
    "                      denoiser=denoiser,\n",
    "                      forwarder=forwarder,\n",
    "                      num_steps=750)"
   ],
   "id": "a88dae5968a609c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "visualize(cloudy_seq=cloudy_seq,\n",
    "          batch=batch,\n",
    "          x0=x0)"
   ],
   "id": "99a229af38134024",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Note**:\n",
    "This notebook shows a toy training pipeline by default. Our fully trained model is trained for 200 epochs on a larger model size. \n",
    "\n",
    "Get the model by running `get_pretrained.get_pretrained_large`."
   ],
   "id": "fda69fd3cab1269d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
