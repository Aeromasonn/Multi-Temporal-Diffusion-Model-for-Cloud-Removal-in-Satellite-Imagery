{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:15:37.169476Z",
     "start_time": "2025-11-24T05:15:37.167237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, random_split, DataLoader"
   ],
   "id": "84e1fb98c567d7fc",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:14:18.536948Z",
     "start_time": "2025-11-24T05:14:18.525949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SatImage_Dataloader(Dataset):\n",
    "    \"\"\"\n",
    "    Mono-temporal Sen2-MTC dataset with patch extraction.\n",
    "\n",
    "    For each time index n:\n",
    "        cloudy[n] has multiple *.tif files\n",
    "        cloudless[n] has one  *.tif file\n",
    "\n",
    "    One cloudy sample for each n -> mono-temporal.\n",
    "    If patch_size is provided:\n",
    "        If center_crop True : return crop from the center of image.\n",
    "        If center_crop False: return a random crop on the image.\n",
    "\n",
    "    If stride is provided:\n",
    "        Enumerate all patches of size patch_size with given stride.\n",
    "        (This multiplies dataset size with deterministic patches.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, route, patch_size=128, stride=128, center_crop=False, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir = route\n",
    "        self.patch_size = patch_size\n",
    "        self.center_crop = center_crop\n",
    "        self.transform = transform\n",
    "        self.stride = stride  # NEW\n",
    "\n",
    "        # List of samples:\n",
    "        # If stride is None:       (cloudy_path, clean_path)\n",
    "        # If stride is not None:   (cloudy_path, clean_path, top, left)\n",
    "        self.samples = []\n",
    "\n",
    "        cloudy_pattern    = r\"(.+?)_(\\d+)_(\\d+)\\.tif\"       # matches n_k (cloud)\n",
    "        cloudless_pattern = r\"(.+?)_(\\d+)\\.tif\"            # matches n (clean)\n",
    "\n",
    "        for tile_name in sorted(os.listdir(route)):\n",
    "            tile_path = os.path.join(route, tile_name)\n",
    "            cloud_dir = os.path.join(tile_path, \"cloud\")\n",
    "            clean_dir = os.path.join(tile_path, \"cloudless\")\n",
    "\n",
    "            if not (os.path.isdir(cloud_dir) and os.path.isdir(clean_dir)):\n",
    "                continue\n",
    "\n",
    "            # 1 — Parse cloudy files grouped by time index n\n",
    "            cloudy_by_n = {}\n",
    "            for fname in sorted(os.listdir(cloud_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudy_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                path = os.path.join(cloud_dir, fname)\n",
    "                cloudy_by_n.setdefault(n, []).append(path)\n",
    "\n",
    "            # 2 — Parse cloudless (clean) files by time index n\n",
    "            clean_by_n = {}\n",
    "            for fname in sorted(os.listdir(clean_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudless_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                clean_by_n[n] = os.path.join(clean_dir, fname)\n",
    "\n",
    "            # 3 — For each n, pick *one* cloudy and match with clean[n]\n",
    "            for n in sorted(cloudy_by_n.keys()):\n",
    "                if n not in clean_by_n:\n",
    "                    print(f\"[WARNING] Tile {tile_name}: time {n} has cloudy but no clean.\")\n",
    "                    continue\n",
    "\n",
    "                cloudy_path = cloudy_by_n[n][0]   # mono-temporal choose first\n",
    "                clean_path = clean_by_n[n]\n",
    "\n",
    "                # If stride is not provided → old behavior: 1 sample per image\n",
    "                if self.stride is None:\n",
    "                    self.samples.append((cloudy_path, clean_path, None, None))\n",
    "                    continue\n",
    "\n",
    "                # Otherwise enumerate patches using stride\n",
    "                # We must load image shape\n",
    "                tmp = tiff.imread(cloudy_path)  # (H, W, C)\n",
    "                H, W, _ = tmp.shape\n",
    "\n",
    "                ps = self.patch_size\n",
    "                st = self.stride\n",
    "\n",
    "                for top in range(0, H - ps + 1, st):\n",
    "                    for left in range(0, W - ps + 1, st):\n",
    "                        self.samples.append((cloudy_path, clean_path, top, left))\n",
    "\n",
    "        print(f\"[Sen2MTC loaded] Total samples (including patches): {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_tif(self, path):\n",
    "        arr = tiff.imread(path)  # (H, W, C)\n",
    "        arr = np.array(arr, dtype=np.float32)\n",
    "        return arr\n",
    "\n",
    "    # Patch extraction helper\n",
    "    def extract_patch(self, img, size):\n",
    "        \"\"\"\n",
    "        img: numpy array shape (C,H,W)\n",
    "        size: int, patch size\n",
    "        returns: (C, size, size)\n",
    "        \"\"\"\n",
    "        _, H, W = img.shape\n",
    "        if size > H or size > W:\n",
    "            raise ValueError(f\"Patch size {size} > image size {(H,W)}\")\n",
    "\n",
    "        if self.center_crop:\n",
    "            top = (H - size) // 2\n",
    "            left = (W - size) // 2\n",
    "        else:\n",
    "            top = np.random.randint(0, H - size + 1)\n",
    "            left = np.random.randint(0, W - size + 1)\n",
    "\n",
    "        patch = img[:, top:top+size, left:left+size]\n",
    "        return patch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cloudy_path, clean_path, top, left = self.samples[idx]\n",
    "\n",
    "        cloudy = self.load_tif(cloudy_path)\n",
    "        clean  = self.load_tif(clean_path)\n",
    "\n",
    "        cloudy = torch.from_numpy(cloudy.transpose(2,0,1))\n",
    "        clean  = torch.from_numpy(clean.transpose(2,0,1))\n",
    "\n",
    "        # Patch extraction\n",
    "        if self.patch_size is not None:\n",
    "            if self.stride is not None:\n",
    "                # predetermined patch from (top, left)\n",
    "                ps = self.patch_size\n",
    "                cloudy = cloudy[:, top:top+ps, left:left+ps]\n",
    "                clean  = clean[:, top:top+ps, left:left+ps]\n",
    "            else:\n",
    "                # center or random crop\n",
    "                cloudy = self.extract_patch(cloudy, self.patch_size)\n",
    "                clean  = self.extract_patch(clean, self.patch_size)\n",
    "\n",
    "        sample = {\n",
    "            \"cloudy\": cloudy,\n",
    "            \"clean\": clean,\n",
    "            \"cloudy_path\": cloudy_path,\n",
    "            \"clean_path\": clean_path\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ],
   "id": "adb1b6b78c97b1c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:14:18.722542Z",
     "start_time": "2025-11-24T05:14:18.718051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_global_stats(dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute global per-channel mean and std over a dataset.\n",
    "    Returns:\n",
    "        mean, std\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    channel_sum = None\n",
    "    channel_sq_sum = None\n",
    "    total_pixels = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"cloudy\"].double()   # (B,C,H,W)\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        if channel_sum is None:\n",
    "            channel_sum = torch.zeros(C, dtype=torch.float64)\n",
    "            channel_sq_sum = torch.zeros(C, dtype=torch.float64)\n",
    "\n",
    "        # Sum over batch and spatial dims\n",
    "        channel_sum += x.sum(dim=[0, 2, 3])\n",
    "        channel_sq_sum += (x ** 2).sum(dim=[0, 2, 3])\n",
    "\n",
    "        total_pixels += B * H * W\n",
    "\n",
    "    mean = channel_sum / total_pixels\n",
    "    std = torch.sqrt(channel_sq_sum / total_pixels - mean**2)\n",
    "\n",
    "    print(\"Global mean:\", mean)\n",
    "    print(\"Global std:\", std)\n",
    "\n",
    "    return mean.float(), std.float()\n",
    "\n",
    "class Normalization:\n",
    "    \"\"\"\n",
    "    Normalize cloudy and clean patches using precomputed mean/std.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.reshape(-1, 1, 1)   # (C,1,1)\n",
    "        self.std  = std.reshape(-1, 1, 1)    # (C,1,1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        cloudy = sample[\"cloudy\"]\n",
    "        clean  = sample[\"clean\"]\n",
    "\n",
    "        cloudy_n = (cloudy - self.mean) / (self.std + 1e-6)\n",
    "        clean_n  = (clean  - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        return {\n",
    "            \"cloudy\": cloudy_n,\n",
    "            \"clean\": clean_n,\n",
    "            \"cloudy_path\": sample[\"cloudy_path\"],\n",
    "            \"clean_path\": sample[\"clean_path\"],\n",
    "        }"
   ],
   "id": "e6ed297b4fb79316",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-24T05:16:04.179633Z",
     "start_time": "2025-11-24T05:15:41.274429Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "############################################################\n",
    "# 1. Your dataset + compute_global_stats + Normalization\n",
    "############################################################\n",
    "\n",
    "# --- paste your ENTIRE SatImage_Dataloader class here ---\n",
    "# --- paste compute_global_stats here ---\n",
    "# --- paste Normalization class here ---\n",
    "\n",
    "###############################################\n",
    "# 2. Precompute everything\n",
    "###############################################\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "route = \"./Sen2_MTC_Mini\"\n",
    "patch_size = 128\n",
    "stride = 128\n",
    "batch_size = 16\n",
    "\n",
    "print(\"STEP 1: Create RAW dataset...\")\n",
    "dataset_raw = SatImage_Dataloader(route=route,\n",
    "                                  patch_size=patch_size,\n",
    "                                  stride=stride,\n",
    "                                  transform=None)\n",
    "\n",
    "print(\"STEP 2: Compute global mean/std...\")\n",
    "mean, std = compute_global_stats(dataset_raw, batch_size=batch_size)\n",
    "\n",
    "print(\"STEP 3: Create normalized dataset...\")\n",
    "normalized_tf = Normalization(mean, std)\n",
    "dataset_norm = SatImage_Dataloader(route=route,\n",
    "                                   patch_size=patch_size,\n",
    "                                   stride=stride,\n",
    "                                   transform=normalized_tf)\n",
    "\n",
    "############################################################\n",
    "# 3. MATERIALIZE THE ENTIRE DATASET INTO MEMORY\n",
    "############################################################\n",
    "\n",
    "print(\"STEP 4: Materialize (load all samples into CPU RAM) ...\")\n",
    "\n",
    "all_cloudy = []\n",
    "all_clean  = []\n",
    "all_cloudy_path = []\n",
    "all_clean_path  = []\n",
    "\n",
    "loader = DataLoader(dataset_norm, batch_size=1, shuffle=False)\n",
    "\n",
    "for sample in tqdm(loader):\n",
    "    # sample[\"cloudy\"] has shape (1,C,H,W) → squeeze B dim\n",
    "    all_cloudy.append(sample[\"cloudy\"].squeeze(0))\n",
    "    all_clean.append(sample[\"clean\"].squeeze(0))\n",
    "    all_cloudy_path.append(sample[\"cloudy_path\"][0])\n",
    "    all_clean_path.append(sample[\"clean_path\"][0])\n",
    "\n",
    "# Stack into tensors or keep list (list is safer for large dataset)\n",
    "# all_cloudy = torch.stack(all_cloudy)\n",
    "# all_clean  = torch.stack(all_clean)\n",
    "\n",
    "print(\"TOTAL PATCHES:\", len(all_cloudy))\n",
    "\n",
    "############################################################\n",
    "# 4. Train/Val/Test Split  (deterministic)\n",
    "############################################################\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "N = len(all_cloudy)\n",
    "train_len = int(train_ratio * N)\n",
    "val_len   = int(val_ratio   * N)\n",
    "test_len  = N - train_len - val_len\n",
    "\n",
    "generator = torch.Generator().manual_seed(2025)\n",
    "indices = torch.randperm(N, generator=generator)\n",
    "\n",
    "train_idx = indices[:train_len]\n",
    "val_idx   = indices[train_len:train_len+val_len]\n",
    "test_idx  = indices[train_len+val_len:]\n",
    "\n",
    "def subset(idx_list):\n",
    "    return {\n",
    "        \"cloudy\": [all_cloudy[i] for i in idx_list],\n",
    "        \"clean\" : [all_clean[i]  for i in idx_list],\n",
    "        \"cloudy_path\": [all_cloudy_path[i] for i in idx_list],\n",
    "        \"clean_path\" : [all_clean_path[i]  for i in idx_list],\n",
    "    }\n",
    "\n",
    "train_set = subset(train_idx)\n",
    "val_set   = subset(val_idx)\n",
    "test_set  = subset(test_idx)\n",
    "\n",
    "############################################################\n",
    "# 5. Save everything to .pt\n",
    "############################################################\n",
    "\n",
    "save_dict = {\n",
    "    \"mean\": mean,\n",
    "    \"std\": std,\n",
    "    \"train_set\": train_set,\n",
    "    \"val_set\": val_set,\n",
    "    \"test_set\": test_set,\n",
    "}\n",
    "\n",
    "torch.save(save_dict, \"sen2mtc_precomputed.pt\")\n",
    "print(\"Saved sen2mtc_precomputed.pt\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Create RAW dataset...\n",
      "[Sen2MTC loaded] Total samples (including patches): 4200\n",
      "STEP 2: Compute global mean/std...\n",
      "Global mean: tensor([1950.8348, 2058.9039, 1980.1758, 3509.9704], dtype=torch.float64)\n",
      "Global std: tensor([2049.4984, 2072.6882, 2218.3611, 1820.3944], dtype=torch.float64)\n",
      "STEP 3: Create normalized dataset...\n",
      "[Sen2MTC loaded] Total samples (including patches): 4200\n",
      "STEP 4: Materialize (load all samples into CPU RAM) ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:12<00:00, 348.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL PATCHES: 4200\n",
      "Saved sen2mtc_precomputed.pt\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:16:08.891750Z",
     "start_time": "2025-11-24T05:16:07.379863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "##############################################\n",
    "# Minimal Dataset wrapper for precomputed data\n",
    "##############################################\n",
    "class PrecomputedDataset(Dataset):\n",
    "    def __init__(self, bag):\n",
    "        self.cloudy = bag[\"cloudy\"]\n",
    "        self.clean  = bag[\"clean\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cloudy)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return {\n",
    "            \"cloudy\": self.cloudy[i].float(),\n",
    "            \"clean\":  self.clean[i].float()\n",
    "        }\n",
    "\n",
    "##############################################\n",
    "# LOAD\n",
    "##############################################\n",
    "data = torch.load(\"sen2mtc_precomputed.pt\")\n",
    "\n",
    "train_set = PrecomputedDataset(data[\"train_set\"])\n",
    "val_set   = PrecomputedDataset(data[\"val_set\"])\n",
    "test_set  = PrecomputedDataset(data[\"test_set\"])\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_set,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_set,  batch_size=batch_size, shuffle=False)\n"
   ],
   "id": "ba3d2701a83c8a40",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:16:09.522195Z",
     "start_time": "2025-11-24T05:16:09.512189Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    print(batch['cloudy'].shape)\n",
    "    print(batch['clean'].shape)\n",
    "    x = batch['cloudy']\n",
    "    print(x.mean(), x.std())\n",
    "    break\n",
    "#[batch_size, channels, height, width] -> [batch_size, channels, patch_size, patch_size]"
   ],
   "id": "919697952c6f830e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 128, 128])\n",
      "torch.Size([16, 4, 128, 128])\n",
      "tensor(-0.0722) tensor(0.7882)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dafadc815d31f76d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
