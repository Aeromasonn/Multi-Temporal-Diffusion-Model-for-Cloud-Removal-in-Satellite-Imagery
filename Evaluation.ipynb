{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T05:17:17.633746Z",
     "start_time": "2025-12-07T05:17:13.409085Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833d6c3018c01114",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T05:26:29.574223Z",
     "start_time": "2025-12-07T05:26:27.483943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['cloudy', 'clean', 'pred'])\n",
      "clean: torch.Size([4101, 4, 128, 128]) torch.float32\n",
      "cloudy: torch.Size([4101, 4, 128, 128]) torch.float32\n",
      "pred: torch.Size([4101, 4, 128, 128]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "path_val = \"./gen_results/val_all.pt\"\n",
    "path_test = \"./gen_results/test_all.pt\"\n",
    "data_val = torch.load(path_val, map_location=\"cpu\")\n",
    "data_test = torch.load(path_test, map_location=\"cpu\")\n",
    "\n",
    "data = {}\n",
    "for key in data_val.keys():\n",
    "    data[key] = torch.cat((data_val[key], data_test[key]), dim=0)\n",
    "\n",
    "print(type(data))\n",
    "print(data.keys())\n",
    "\n",
    "clean  = data[\"clean\"]\n",
    "cloudy = data[\"cloudy\"]\n",
    "pred   = data[\"pred\"]\n",
    "\n",
    "print(\"clean:\",  clean.shape,  clean.dtype)\n",
    "print(\"cloudy:\", cloudy.shape, cloudy.dtype)\n",
    "print(\"pred:\",   pred.shape,   pred.dtype)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a63594a4324550",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T05:26:32.876853Z",
     "start_time": "2025-12-07T05:26:32.606893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained large model loaded successfully.\n",
      "The model has 5125701 parameters.\n"
     ]
    }
   ],
   "source": [
    "from wrapped.get_pretrained import get_pretrained_large\n",
    "cloud_enc_pth = './Ckpts/cloud_enc_200e_FullData.pth'\n",
    "denoiser_pth = './Ckpts/denoiser_200e_FullData.pth'\n",
    "cloud_encoder, forwarder, denoiser = get_pretrained_large(device=device,\n",
    "                                                          cloud_enc_pth=cloud_enc_pth,\n",
    "                                                          denoiser_pth=denoiser_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d09e7fa4a137e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T05:26:35.178863Z",
     "start_time": "2025-12-07T05:26:34.331480Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PyCharm 2024.2.1\\Projects\\pythonProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\PyCharm 2024.2.1\\Projects\\pythonProject\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: D:\\PyCharm 2024.2.1\\Projects\\pythonProject\\.venv\\Lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LPIPS(\n",
       "  (scaling_layer): ScalingLayer()\n",
       "  (net): vgg16(\n",
       "    (slice1): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice2): Sequential(\n",
       "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (6): ReLU(inplace=True)\n",
       "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (8): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice3): Sequential(\n",
       "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (11): ReLU(inplace=True)\n",
       "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (13): ReLU(inplace=True)\n",
       "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (15): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice4): Sequential(\n",
       "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (18): ReLU(inplace=True)\n",
       "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (20): ReLU(inplace=True)\n",
       "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (22): ReLU(inplace=True)\n",
       "    )\n",
       "    (slice5): Sequential(\n",
       "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (25): ReLU(inplace=True)\n",
       "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (27): ReLU(inplace=True)\n",
       "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (29): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (lin0): NetLinLayer(\n",
       "    (model): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (lin1): NetLinLayer(\n",
       "    (model): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (lin2): NetLinLayer(\n",
       "    (model): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (lin3): NetLinLayer(\n",
       "    (model): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (lin4): NetLinLayer(\n",
       "    (model): Sequential(\n",
       "      (0): Dropout(p=0.5, inplace=False)\n",
       "      (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (lins): ModuleList(\n",
       "    (0): NetLinLayer(\n",
       "      (model): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (1): NetLinLayer(\n",
       "      (model): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (2): NetLinLayer(\n",
       "      (model): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (3-4): 2 x NetLinLayer(\n",
       "      (model): Sequential(\n",
       "        (0): Dropout(p=0.5, inplace=False)\n",
       "        (1): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wrapped.evaluation as evaluation\n",
    "importlib.reload(evaluation)\n",
    "from wrapped.evaluation import evaluate_over_precomputed\n",
    "import lpips\n",
    "\n",
    "lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
    "lpips_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad40f45c0da3992a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-07T05:26:45.012591Z",
     "start_time": "2025-12-07T05:26:36.483668Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: D:\\PyCharm 2024.2.1\\Projects\\pythonProject\\.venv\\Lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 129/129 [00:12<00:00, 10.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-batch metrics example: {'MAE': 0.010509842075407505, 'PSNR': 24.852405548095703, 'SSIM': 0.9145927429199219, 'LPIPS': 0.07596463710069656}\n",
      "Dataset summary: {'MAE_mean': 0.017053022980690002, 'MAE_std': 0.0037360077258199453, 'PSNR_mean': 22.694576263427734, 'PSNR_std': 1.3518364429473877, 'SSIM_mean': 0.8884437084197998, 'SSIM_std': 0.017557499930262566, 'LPIPS_mean': 0.10063502192497253, 'LPIPS_std': 0.02081654965877533}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(evaluation)\n",
    "\n",
    "lpips_model = lpips.LPIPS(net='vgg').to(device)\n",
    "lpips_model.eval()\n",
    "\n",
    "all_metrics, summary = evaluate_over_precomputed(\n",
    "    data=data,\n",
    "    batch_size=32,\n",
    "    max_val=1.0,\n",
    "    lpips_model=lpips_model,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(\"Per-batch metrics example:\", all_metrics[0])\n",
    "print(\"Dataset summary:\", summary)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4375a3d3384182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
