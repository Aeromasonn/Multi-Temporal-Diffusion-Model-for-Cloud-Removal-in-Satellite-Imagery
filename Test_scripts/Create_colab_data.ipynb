{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T18:35:02.704053Z",
     "start_time": "2025-12-01T18:34:55.464961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, random_split, DataLoader"
   ],
   "id": "84e1fb98c567d7fc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-24T05:14:18.536948Z",
     "start_time": "2025-11-24T05:14:18.525949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SatImage_Dataloader_1v1(Dataset):\n",
    "    def __init__(self, route, patch_size=128, stride=128, center_crop=False, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir = route\n",
    "        self.patch_size = patch_size\n",
    "        self.center_crop = center_crop\n",
    "        self.transform = transform\n",
    "        self.stride = stride\n",
    "\n",
    "        # List of samples:\n",
    "        # If stride is None:       (cloudy_path, clean_path)\n",
    "        # If stride is not None:   (cloudy_path, clean_path, top, left)\n",
    "        self.samples = []\n",
    "\n",
    "        cloudy_pattern    = r\"(.+?)_(\\d+)_(\\d+)\\.tif\"       # matches n_k (cloud)\n",
    "        cloudless_pattern = r\"(.+?)_(\\d+)\\.tif\"            # matches n (clean)\n",
    "\n",
    "        for tile_name in sorted(os.listdir(route)):\n",
    "            tile_path = os.path.join(route, tile_name)\n",
    "            cloud_dir = os.path.join(tile_path, \"cloud\")\n",
    "            clean_dir = os.path.join(tile_path, \"cloudless\")\n",
    "\n",
    "            if not (os.path.isdir(cloud_dir) and os.path.isdir(clean_dir)):\n",
    "                continue\n",
    "\n",
    "            # 1 — Parse cloudy files grouped by time index n\n",
    "            cloudy_by_n = {}\n",
    "            for fname in sorted(os.listdir(cloud_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudy_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                path = os.path.join(cloud_dir, fname)\n",
    "                cloudy_by_n.setdefault(n, []).append(path)\n",
    "\n",
    "            # 2 — Parse cloudless (clean) files by time index n\n",
    "            clean_by_n = {}\n",
    "            for fname in sorted(os.listdir(clean_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudless_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                clean_by_n[n] = os.path.join(clean_dir, fname)\n",
    "\n",
    "            # 3 — For each n, pick *one* cloudy and match with clean[n]\n",
    "            for n in sorted(cloudy_by_n.keys()):\n",
    "                if n not in clean_by_n:\n",
    "                    print(f\"[WARNING] Tile {tile_name}: time {n} has cloudy but no clean.\")\n",
    "                    continue\n",
    "\n",
    "                cloudy_path = cloudy_by_n[n][0]   # mono-temporal choose first\n",
    "                clean_path = clean_by_n[n]\n",
    "\n",
    "                # If stride is not provided → old behavior: 1 sample per image\n",
    "                if self.stride is None:\n",
    "                    self.samples.append((cloudy_path, clean_path, None, None))\n",
    "                    continue\n",
    "\n",
    "                # Otherwise enumerate patches using stride\n",
    "                tmp = tiff.imread(cloudy_path)  # (H, W, C)\n",
    "                H, W, _ = tmp.shape\n",
    "\n",
    "                ps = self.patch_size\n",
    "                st = self.stride\n",
    "\n",
    "                for top in range(0, H - ps + 1, st):\n",
    "                    for left in range(0, W - ps + 1, st):\n",
    "                        self.samples.append((cloudy_path, clean_path, top, left))\n",
    "\n",
    "        print(f\"[Sen2MTC loaded] Total samples (including patches): {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_tif(self, path):\n",
    "        arr = tiff.imread(path)  # (H, W, C)\n",
    "        arr = np.array(arr, dtype=np.float32)\n",
    "        return arr\n",
    "\n",
    "    # Patch extraction helper\n",
    "    def extract_patch(self, img, size):\n",
    "        _, H, W = img.shape\n",
    "        if size > H or size > W:\n",
    "            raise ValueError(f\"Patch size {size} > image size {(H,W)}\")\n",
    "\n",
    "        if self.center_crop:\n",
    "            top = (H - size) // 2\n",
    "            left = (W - size) // 2\n",
    "        else:\n",
    "            top = np.random.randint(0, H - size + 1)\n",
    "            left = np.random.randint(0, W - size + 1)\n",
    "\n",
    "        patch = img[:, top:top+size, left:left+size]\n",
    "        return patch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cloudy_path, clean_path, top, left = self.samples[idx]\n",
    "\n",
    "        cloudy = self.load_tif(cloudy_path)\n",
    "        clean  = self.load_tif(clean_path)\n",
    "\n",
    "        cloudy = torch.from_numpy(cloudy.transpose(2,0,1))\n",
    "        clean  = torch.from_numpy(clean.transpose(2,0,1))\n",
    "\n",
    "        # Patch extraction\n",
    "        if self.patch_size is not None:\n",
    "            if self.stride is not None:\n",
    "                # predetermined patch from (top, left)\n",
    "                ps = self.patch_size\n",
    "                cloudy = cloudy[:, top:top+ps, left:left+ps]\n",
    "                clean  = clean[:, top:top+ps, left:left+ps]\n",
    "            else:\n",
    "                # center or random crop\n",
    "                cloudy = self.extract_patch(cloudy, self.patch_size)\n",
    "                clean  = self.extract_patch(clean, self.patch_size)\n",
    "\n",
    "        sample = {\n",
    "            \"cloudy\": cloudy,\n",
    "            \"clean\": clean,\n",
    "            \"cloudy_path\": cloudy_path,\n",
    "            \"clean_path\": clean_path\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ],
   "id": "adb1b6b78c97b1c2",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T02:53:34.458730Z",
     "start_time": "2025-11-25T02:53:34.438418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_global_stats(dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute global per-channel mean and std over a dataset.\n",
    "    Returns:\n",
    "        mean, std\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    channel_sum = None\n",
    "    channel_sq_sum = None\n",
    "    total_pixels = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"cloud\"].double()   # (B,C,H,W)\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        if channel_sum is None:\n",
    "            channel_sum = torch.zeros(C, dtype=torch.float64)\n",
    "            channel_sq_sum = torch.zeros(C, dtype=torch.float64)\n",
    "\n",
    "        # Sum over batch and spatial dims\n",
    "        channel_sum += x.sum(dim=[0, 2, 3])\n",
    "        channel_sq_sum += (x ** 2).sum(dim=[0, 2, 3])\n",
    "\n",
    "        total_pixels += B * H * W\n",
    "\n",
    "    mean = channel_sum / total_pixels\n",
    "    std = torch.sqrt(channel_sq_sum / total_pixels - mean**2)\n",
    "\n",
    "    print(\"Global mean:\", mean)\n",
    "    print(\"Global std:\", std)\n",
    "\n",
    "    return mean.float(), std.float()\n",
    "\n",
    "class Normalization_1v1:\n",
    "    \"\"\"\n",
    "    Normalize cloudy and clean patches using precomputed mean/std.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.reshape(-1, 1, 1)   # (C,1,1)\n",
    "        self.std  = std.reshape(-1, 1, 1)    # (C,1,1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        cloudy = sample[\"cloudy\"]\n",
    "        clean  = sample[\"clean\"]\n",
    "\n",
    "        cloudy_n = (cloudy - self.mean) / (self.std + 1e-6)\n",
    "        clean_n  = (clean  - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        return {\n",
    "            \"cloudy\": cloudy_n,\n",
    "            \"clean\": clean_n,\n",
    "            \"cloudy_path\": sample[\"cloudy_path\"],\n",
    "            \"clean_path\": sample[\"clean_path\"],\n",
    "        }"
   ],
   "id": "e6ed297b4fb79316",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-01T18:35:14.772750Z",
     "start_time": "2025-12-01T18:35:14.738387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SatImage_Dataloader_3v1(Dataset):\n",
    "    def __init__(self, route, patch_size=128, stride=128,\n",
    "                 center_crop=False, transform=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.root_dir = route\n",
    "        self.patch_size = patch_size\n",
    "        self.center_crop = center_crop\n",
    "        self.transform = transform\n",
    "        self.stride = stride\n",
    "        self.samples = []\n",
    "\n",
    "        cloudy_pattern = r\"(.+?)_(\\d+)_(\\d+)\\.tif\"\n",
    "        clean_pattern  = r\"(.+?)_(\\d+)\\.tif\"\n",
    "\n",
    "        for tile_name in sorted(os.listdir(route)):\n",
    "            tile_path = os.path.join(route, tile_name)\n",
    "            cloud_dir = os.path.join(tile_path, \"cloud\")\n",
    "            clean_dir = os.path.join(tile_path, \"cloudless\")\n",
    "\n",
    "            if not (os.path.isdir(cloud_dir) and os.path.isdir(clean_dir)):\n",
    "                continue\n",
    "\n",
    "            cloudy_by_n = {}\n",
    "            for fname in sorted(os.listdir(cloud_dir)):\n",
    "                if fname.endswith(\".tif\"):\n",
    "                    m = re.match(cloudy_pattern, fname)\n",
    "                    if m:\n",
    "                        n = int(m.group(2))\n",
    "                        cloudy_by_n.setdefault(n, []).append(\n",
    "                            os.path.join(cloud_dir, fname)\n",
    "                        )\n",
    "\n",
    "            clean_by_n = {}\n",
    "            for fname in sorted(os.listdir(clean_dir)):\n",
    "                if fname.endswith(\".tif\"):\n",
    "                    m = re.match(clean_pattern, fname)\n",
    "                    if m:\n",
    "                        n = int(m.group(2))\n",
    "                        clean_by_n[n] = os.path.join(clean_dir, fname)\n",
    "\n",
    "            for n in sorted(cloudy_by_n.keys()):\n",
    "                if n not in clean_by_n: \n",
    "                    continue\n",
    "\n",
    "                cloudy_paths = sorted(cloudy_by_n[n])\n",
    "                if len(cloudy_paths) < 3:\n",
    "                    continue\n",
    "                if len(cloudy_paths) > 3:\n",
    "                    cloudy_paths = cloudy_paths[:3]\n",
    "\n",
    "                clean_path = clean_by_n[n]\n",
    "\n",
    "                # patch enumeration\n",
    "                if self.stride is None:\n",
    "                    self.samples.append((cloudy_paths, clean_path, None, None))\n",
    "                else:\n",
    "                    tmp = tiff.imread(cloudy_paths[0])\n",
    "                    H, W, _ = tmp.shape\n",
    "\n",
    "                    ps = self.patch_size\n",
    "                    st = self.stride\n",
    "\n",
    "                    for top in range(0, H-ps+1, st):\n",
    "                        for left in range(0, W-ps+1, st):\n",
    "                            self.samples.append((cloudy_paths, clean_path, top, left))\n",
    "\n",
    "        print(f\"[Loaded minimal MT dataset] {len(self.samples)} samples\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_tif(self, path):\n",
    "        arr = tiff.imread(path).astype(np.float32)\n",
    "        return arr  # (H,W,C)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cloudy_paths, clean_path, top, left = self.samples[idx]\n",
    "\n",
    "        # clean\n",
    "        clean_np = self.load_tif(clean_path).transpose(2,0,1)\n",
    "        clean = torch.from_numpy(clean_np)  # (C,H,W)\n",
    "\n",
    "        # cloudy sequence\n",
    "        seq_list = []\n",
    "        for p in cloudy_paths:\n",
    "            c_np = self.load_tif(p).transpose(2,0,1)\n",
    "            seq_list.append(torch.from_numpy(c_np))\n",
    "        seq = torch.stack(seq_list, dim=0)  # (T,C,H,W)\n",
    "\n",
    "        # patching\n",
    "        if self.patch_size is not None:\n",
    "            ps = self.patch_size\n",
    "\n",
    "            if self.stride is not None:\n",
    "                clean = clean[:, top:top+ps, left:left+ps]\n",
    "                seq   = seq[:, :, top:top+ps, left:left+ps]\n",
    "            else:\n",
    "                _, H, W = clean.shape\n",
    "                if self.center_crop:\n",
    "                    top = (H-ps)//2\n",
    "                    left = (W-ps)//2\n",
    "                else:\n",
    "                    top = np.random.randint(0, H-ps+1)\n",
    "                    left = np.random.randint(0, W-ps+1)\n",
    "                clean = clean[:, top:top+ps, left:left+ps]\n",
    "                seq   = seq[:, :, top:top+ps, left:left+ps]\n",
    "\n",
    "        sample = {\"clean\": clean, \"cloudy_seq\": seq}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "\n",
    "class Normalization_3v1:\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.reshape(-1,1,1)\n",
    "        self.std  = std.reshape(-1,1,1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        clean = sample[\"clean\"]                # (C,H,W)\n",
    "        seq   = sample[\"cloudy_seq\"]           # (T,C,H,W)\n",
    "\n",
    "        clean_n = (clean - self.mean) / (self.std + 1e-6)\n",
    "        seq_n   = (seq   - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        return {\n",
    "            \"clean\": clean_n,\n",
    "            \"cloudy_seq\": seq_n\n",
    "        }\n",
    "\n",
    "def compute_global_stats_3v1(root):\n",
    "    \"\"\"\n",
    "    Compute global mean/std over ALL raw TIFF images inside:\n",
    "        <tile>/cloud/*.tif\n",
    "        <tile>/cloudless/*.tif\n",
    "    \n",
    "    Returns torch tensors:  mean (C,), std (C,)\n",
    "    \"\"\"\n",
    "\n",
    "    sum_channels = None\n",
    "    sum_sq_channels = None\n",
    "    count_pixels = 0\n",
    "\n",
    "    # list all tiles\n",
    "    tile_names = sorted(os.listdir(root))\n",
    "\n",
    "    all_images = []\n",
    "\n",
    "    for tile in tile_names:\n",
    "        tile_dir = os.path.join(root, tile)\n",
    "        cloud_dir = os.path.join(tile_dir, \"cloud\")\n",
    "        clean_dir = os.path.join(tile_dir, \"cloudless\")\n",
    "\n",
    "        if not (os.path.isdir(cloud_dir) and os.path.isdir(clean_dir)):\n",
    "            continue\n",
    "\n",
    "        # collect all tif paths\n",
    "        for subdir in [cloud_dir, clean_dir]:\n",
    "            for fname in os.listdir(subdir):\n",
    "                if fname.endswith(\".tif\"):\n",
    "                    all_images.append(os.path.join(subdir, fname))\n",
    "\n",
    "    print(f\"[compute_global_stats] Found {len(all_images)} images.\")\n",
    "\n",
    "    # iterate through images\n",
    "    for img_path in tqdm(all_images, desc=\"Computing global mean/std\"):\n",
    "        arr = tiff.imread(img_path).astype(np.float32)   # (H,W,C)\n",
    "        C = arr.shape[2]\n",
    "\n",
    "        if sum_channels is None:\n",
    "            sum_channels = np.zeros(C, dtype=np.float64)\n",
    "            sum_sq_channels = np.zeros(C, dtype=np.float64)\n",
    "\n",
    "        # flatten H,W dims\n",
    "        flat = arr.reshape(-1, C)   # (H*W, C)\n",
    "        sum_channels += flat.sum(axis=0)\n",
    "        sum_sq_channels += (flat ** 2).sum(axis=0)\n",
    "        count_pixels += flat.shape[0]\n",
    "\n",
    "    # compute mean/std\n",
    "    mean = sum_channels / count_pixels\n",
    "    var = (sum_sq_channels / count_pixels) - (mean ** 2)\n",
    "    std = np.sqrt(var)\n",
    "\n",
    "    mean = torch.tensor(mean, dtype=torch.float32)\n",
    "    std  = torch.tensor(std, dtype=torch.float32)\n",
    "\n",
    "    print(\"Global mean:\", mean)\n",
    "    print(\"Global std :\", std)\n",
    "\n",
    "    return mean, std\n"
   ],
   "id": "b180b53f9a50cb51",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-01T18:39:59.490099Z",
     "start_time": "2025-12-01T18:36:03.559165Z"
    }
   },
   "source": [
    "route = \"./Sen2_MTC/dataset/Sen2_MTC\"\n",
    "ps = 128\n",
    "st = 128\n",
    "batch_size = 16\n",
    "\n",
    "dataset_raw = SatImage_Dataloader_3v1(\n",
    "    route=route,\n",
    "    patch_size=ps,\n",
    "    stride=st,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "mean, std = compute_global_stats_3v1(route)\n",
    "\n",
    "dataset_norm = SatImage_Dataloader_3v1(\n",
    "    route=route,\n",
    "    patch_size=ps,\n",
    "    stride=st,\n",
    "    transform=Normalization_3v1(mean, std)\n",
    ")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio   = 0.15\n",
    "test_ratio  = 0.15\n",
    "\n",
    "total       = len(dataset_norm)\n",
    "train_len   = int(total * train_ratio)\n",
    "val_len     = int(total * val_ratio)\n",
    "test_len    = total - train_len - val_len\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    dataset_norm,\n",
    "    [train_len, val_len, test_len],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "def pack_split(split):\n",
    "    \"\"\"Convert a Subset into a list of {cloudy_seq, clean} dicts.\"\"\"\n",
    "    out = []\n",
    "    for i in range(len(split)):\n",
    "        item = split[i]\n",
    "        out.append({\n",
    "            \"cloudy_seq\": item[\"cloudy_seq\"],\n",
    "            \"clean\": item[\"clean\"]\n",
    "        })\n",
    "    return out\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"train\": pack_split(train_set),\n",
    "    \"val\":   pack_split(val_set),\n",
    "    \"test\":  pack_split(test_set)\n",
    "}\n",
    "\n",
    "torch.save(data, \"./Ckpts/Sen2MTC_FULL_3v1_norm.pt\")\n",
    "print(\"Saved → Sen2MTC_all.pt\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Loaded minimal MT dataset] 13668 samples\n",
      "[compute_global_stats] Found 13669 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing global mean/std: 100%|██████████| 13669/13669 [01:07<00:00, 202.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global mean: tensor([1711.6575, 1720.1365, 1585.7429, 3117.7529])\n",
      "Global std : tensor([1862.0779, 1880.4310, 2019.5642, 1677.4390])\n",
      "[Loaded minimal MT dataset] 13668 samples\n",
      "Saved → Sen2MTC_all.pt\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:36:50.403710Z",
     "start_time": "2025-11-25T03:36:46.834015Z"
    }
   },
   "cell_type": "code",
   "source": "data = torch.load(\"./Ckpts/Sen2MTC_Mini_3v1_norm.pt\", map_location=\"cpu\")",
   "id": "dafadc815d31f76d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:36:50.629660Z",
     "start_time": "2025-11-25T03:36:50.621497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PrecomputedSen2MTC(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        # data_list is a list of dicts:\n",
    "        # [{\"cloudy_seq\": tensor, \"clean\": tensor}, ...]\n",
    "        self.data = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"cloudy_seq\": item[\"cloudy_seq\"],\n",
    "            \"clean\": item[\"clean\"]\n",
    "        }\n",
    "\n",
    "def collate_mt(batch):\n",
    "    # batch: list of {\"cloudy_seq\":..., \"clean\":...}\n",
    "\n",
    "    cloudy = [b[\"cloudy_seq\"] for b in batch]   # list of (T,C,H,W)\n",
    "    clean  = [b[\"clean\"]      for b in batch]   # list of (C,H,W)\n",
    "\n",
    "    cloudy = torch.stack(cloudy, dim=0)    # (B,T,C,H,W)\n",
    "    clean  = torch.stack(clean,  dim=0)    # (B,C,H,W)\n",
    "\n",
    "    return {\n",
    "        \"cloudy_seq\": cloudy,\n",
    "        \"clean\": clean\n",
    "    }\n"
   ],
   "id": "22a3b3670f694e22",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:36:53.005081Z",
     "start_time": "2025-11-25T03:36:52.993408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_set = PrecomputedSen2MTC(data[\"train\"])\n",
    "val_set   = PrecomputedSen2MTC(data[\"val\"])\n",
    "test_set  = PrecomputedSen2MTC(data[\"test\"])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=16,\n",
    "                          shuffle=True, collate_fn=collate_mt)\n",
    "\n",
    "val_loader   = DataLoader(val_set,   batch_size=16,\n",
    "                          shuffle=False, collate_fn=collate_mt)\n",
    "\n",
    "test_loader  = DataLoader(test_set,  batch_size=16,\n",
    "                          shuffle=False, collate_fn=collate_mt)\n"
   ],
   "id": "99ca903d0c4e2a9a",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:36:53.352034Z",
     "start_time": "2025-11-25T03:36:53.333380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch = next(iter(train_loader))\n",
    "\n",
    "print(batch[\"cloudy_seq\"].shape)   # (B,T,C,H,W)\n",
    "print(batch[\"clean\"].shape)        # (B,C,H,W)\n"
   ],
   "id": "eb52618c081d6f60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 4, 128, 128])\n",
      "torch.Size([16, 4, 128, 128])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:37:00.723173Z",
     "start_time": "2025-11-25T03:37:00.713966Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_set[0])",
   "id": "3a7ac56112fea472",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cloudy_seq': tensor([[[[ 1.7398e+00,  1.5795e+00,  1.3616e+00,  ...,  1.6607e+00,\n",
      "            1.5304e+00,  1.3295e+00],\n",
      "          [ 1.6714e+00,  1.5710e+00,  1.4855e+00,  ...,  1.6223e+00,\n",
      "            1.4812e+00,  1.3413e+00],\n",
      "          [ 1.5432e+00,  1.5005e+00,  1.5689e+00,  ...,  1.6479e+00,\n",
      "            1.5176e+00,  1.3680e+00],\n",
      "          ...,\n",
      "          [-3.6172e-01, -3.8950e-01, -3.5264e-01,  ...,  3.0068e-01,\n",
      "            3.3166e-01,  3.4555e-01],\n",
      "          [-3.2647e-01, -3.0029e-01, -2.2817e-01,  ...,  2.4833e-01,\n",
      "            2.7076e-01,  3.4555e-01],\n",
      "          [-2.7412e-01, -2.2924e-01, -1.8544e-01,  ...,  2.7183e-01,\n",
      "            3.1670e-01,  4.1927e-01]],\n",
      "\n",
      "         [[ 1.8813e+00,  1.8304e+00,  1.6671e+00,  ...,  1.8049e+00,\n",
      "            1.6056e+00,  1.3722e+00],\n",
      "          [ 1.8198e+00,  1.6628e+00,  1.5080e+00,  ...,  1.8071e+00,\n",
      "            1.5737e+00,  1.3128e+00],\n",
      "          [ 1.7286e+00,  1.5037e+00,  1.4040e+00,  ...,  1.7498e+00,\n",
      "            1.6034e+00,  1.3552e+00],\n",
      "          ...,\n",
      "          [-2.1660e-01, -2.1448e-01, -1.7311e-01,  ...,  5.2266e-01,\n",
      "            5.3644e-01,  5.1629e-01],\n",
      "          [-2.9508e-01, -2.7917e-01, -2.4842e-01,  ...,  4.4311e-01,\n",
      "            4.8235e-01,  4.9296e-01],\n",
      "          [-3.3114e-01, -2.9190e-01, -2.6963e-01,  ...,  3.4447e-01,\n",
      "            3.6144e-01,  3.9432e-01]],\n",
      "\n",
      "         [[ 1.7838e+00,  1.7699e+00,  1.7262e+00,  ...,  1.5914e+00,\n",
      "            1.5279e+00,  1.4208e+00],\n",
      "          [ 1.9385e+00,  1.8452e+00,  1.7362e+00,  ...,  1.7084e+00,\n",
      "            1.6271e+00,  1.4942e+00],\n",
      "          [ 1.9623e+00,  1.8730e+00,  1.8234e+00,  ...,  1.7520e+00,\n",
      "            1.5874e+00,  1.4129e+00],\n",
      "          ...,\n",
      "          [-9.8406e-02, -2.8990e-02, -8.1548e-02,  ...,  4.7874e-01,\n",
      "            4.7874e-01,  4.8271e-01],\n",
      "          [-1.6187e-01, -1.0634e-01, -7.6589e-02,  ...,  4.6089e-01,\n",
      "            4.5692e-01,  4.6486e-01],\n",
      "          [-1.7972e-01, -1.3311e-01, -6.4689e-02,  ...,  4.8171e-01,\n",
      "            4.9262e-01,  5.1940e-01]],\n",
      "\n",
      "         [[ 1.4504e+00,  1.4051e+00,  1.2978e+00,  ...,  1.4027e+00,\n",
      "            1.3312e+00,  1.2191e+00],\n",
      "          [ 1.4958e+00,  1.4242e+00,  1.3264e+00,  ...,  1.4934e+00,\n",
      "            1.3359e+00,  1.1523e+00],\n",
      "          [ 1.4051e+00,  1.2787e+00,  1.2334e+00,  ...,  1.4838e+00,\n",
      "            1.2668e+00,  1.0759e+00],\n",
      "          ...,\n",
      "          [ 4.1947e-02,  2.5250e-02, -3.0803e-02,  ...,  4.2716e-01,\n",
      "            3.9735e-01,  3.6753e-01],\n",
      "          [-1.1429e-01, -1.5722e-01, -1.6915e-01,  ...,  4.3790e-01,\n",
      "            4.6294e-01,  4.7964e-01],\n",
      "          [-4.0767e-01, -4.1006e-01, -3.5400e-01,  ...,  4.1762e-01,\n",
      "            4.5698e-01,  4.5102e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1215e-01, -4.1514e-01, -3.4890e-01,  ...,  2.5970e-03,\n",
      "           -3.0523e-02,  3.6653e-03],\n",
      "          [-1.6834e-01, -4.1301e-01, -4.3170e-01,  ..., -3.8002e-02,\n",
      "           -4.3344e-02,  1.1144e-02],\n",
      "          [-2.1642e-01, -4.2850e-01, -3.4303e-01,  ..., -5.0822e-02,\n",
      "           -4.3344e-02, -2.8386e-02],\n",
      "          ...,\n",
      "          [-4.2048e-01, -4.4399e-01, -4.5734e-01,  ..., -2.5168e-01,\n",
      "           -1.9719e-01, -1.3095e-01],\n",
      "          [-4.2850e-01, -4.2155e-01, -4.7177e-01,  ..., -1.2775e-01,\n",
      "           -6.6848e-02,  6.8705e-03],\n",
      "          [-4.1995e-01, -4.2903e-01, -4.6001e-01,  ..., -2.0040e-01,\n",
      "           -1.6193e-01,  5.8153e-02]],\n",
      "\n",
      "         [[-2.8448e-01, -3.7410e-01, -3.4016e-01,  ..., -2.0387e-01,\n",
      "           -1.9857e-01, -1.8478e-01],\n",
      "          [-3.1205e-01, -3.7410e-01, -3.5872e-01,  ..., -2.1554e-01,\n",
      "           -2.0175e-01, -1.8054e-01],\n",
      "          [-3.0251e-01, -3.6296e-01, -3.5289e-01,  ..., -1.9538e-01,\n",
      "           -1.9645e-01, -2.0493e-01],\n",
      "          ...,\n",
      "          [-3.8789e-01, -3.8842e-01, -3.9107e-01,  ..., -2.5690e-01,\n",
      "           -1.6144e-01, -2.5685e-02],\n",
      "          [-3.7463e-01, -3.7092e-01, -3.8948e-01,  ..., -1.5720e-01,\n",
      "           -3.4170e-02,  5.3861e-02],\n",
      "          [-3.2849e-01, -3.4440e-01, -3.5607e-01,  ..., -2.3463e-01,\n",
      "           -1.9538e-01, -7.6547e-03]],\n",
      "\n",
      "         [[-3.4781e-01, -4.1524e-01, -4.0285e-01,  ..., -2.5310e-01,\n",
      "           -2.5310e-01, -2.5856e-01],\n",
      "          [-3.4781e-01, -4.1722e-01, -4.2516e-01,  ..., -2.6352e-01,\n",
      "           -2.6153e-01, -2.5459e-01],\n",
      "          [-3.6367e-01, -4.1871e-01, -3.9541e-01,  ..., -2.8038e-01,\n",
      "           -2.6500e-01, -2.6798e-01],\n",
      "          ...,\n",
      "          [-4.2367e-01, -4.1871e-01, -4.4003e-01,  ..., -2.3129e-01,\n",
      "            6.6210e-02,  2.6553e-01],\n",
      "          [-4.2020e-01, -4.2565e-01, -4.3111e-01,  ..., -1.0832e-01,\n",
      "            5.5301e-02,  3.1412e-01],\n",
      "          [-4.2020e-01, -4.3408e-01, -4.3557e-01,  ..., -3.3541e-01,\n",
      "           -2.7988e-01,  1.5635e-02]],\n",
      "\n",
      "         [[-1.8823e-01,  4.2120e-01,  3.5918e-01,  ..., -4.3391e-01,\n",
      "           -4.3391e-01, -4.0409e-01],\n",
      "          [-2.5382e-01,  3.7827e-01,  4.6294e-01,  ..., -4.4345e-01,\n",
      "           -4.5895e-01, -4.1841e-01],\n",
      "          [ 4.4332e-02,  2.0772e-01,  8.7266e-02,  ..., -4.3391e-01,\n",
      "           -4.2318e-01, -3.7309e-01],\n",
      "          ...,\n",
      "          [ 1.9699e-01,  1.5048e-01,  1.3139e-01,  ..., -1.4291e-01,\n",
      "           -9.9975e-02,  9.6807e-02],\n",
      "          [ 6.9377e-02,  1.4516e-02,  8.9651e-02,  ..., -2.2759e-01,\n",
      "           -1.3337e-01,  1.3497e-01],\n",
      "          [ 3.8369e-02, -9.8779e-04,  7.7725e-02,  ..., -9.3361e-03,\n",
      "            2.4588e-01,  6.1029e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4805e-01, -9.8900e-02,  4.9606e-02,  ..., -1.7048e-01,\n",
      "           -6.3643e-02,  5.4948e-02],\n",
      "          [-1.3309e-01, -2.2283e-01, -1.2881e-01,  ..., -1.8758e-01,\n",
      "           -9.5695e-02,  7.9389e-03],\n",
      "          [-1.3736e-01, -2.9068e-01, -2.4741e-01,  ..., -1.9185e-01,\n",
      "           -1.4377e-01, -6.4711e-02],\n",
      "          ...,\n",
      "          [-1.5659e-01, -1.8758e-01, -2.0040e-01,  ..., -2.8694e-01,\n",
      "           -1.8971e-01, -1.7369e-01],\n",
      "          [-2.1642e-01, -1.5232e-01, -2.0467e-01,  ..., -1.6834e-01,\n",
      "           -5.8301e-02, -4.2275e-02],\n",
      "          [-1.6407e-01, -1.6514e-01, -2.2176e-01,  ..., -4.1207e-02,\n",
      "            9.7683e-02,  1.0196e-01]],\n",
      "\n",
      "         [[-2.0599e-01, -1.6357e-01, -8.4020e-02,  ..., -2.2720e-01,\n",
      "           -1.3387e-01, -5.8565e-02],\n",
      "          [-2.0917e-01, -2.1235e-01, -1.6569e-01,  ..., -2.4948e-01,\n",
      "           -1.6144e-01, -1.0099e-01],\n",
      "          [-2.1660e-01, -2.3675e-01, -2.2932e-01,  ..., -2.5902e-01,\n",
      "           -2.2084e-01, -1.7205e-01],\n",
      "          ...,\n",
      "          [-1.2857e-01, -1.6038e-01, -1.7735e-01,  ..., -2.5266e-01,\n",
      "           -1.8478e-01, -1.3069e-01],\n",
      "          [-1.5826e-01, -1.2538e-01, -1.7205e-01,  ..., -8.0838e-02,\n",
      "            3.5831e-02,  6.4468e-02],\n",
      "          [-1.1690e-01, -1.0947e-01, -1.7841e-01,  ..., -4.9019e-02,\n",
      "            5.7043e-02,  1.5568e-01]],\n",
      "\n",
      "         [[-2.3922e-01, -2.1344e-01, -1.5791e-01,  ..., -1.8270e-01,\n",
      "           -1.0634e-01, -5.9731e-02],\n",
      "          [-2.4368e-01, -2.4220e-01, -2.0650e-01,  ..., -1.9955e-01,\n",
      "           -1.2320e-01, -1.0336e-01],\n",
      "          [-2.4368e-01, -2.4567e-01, -2.5806e-01,  ..., -1.9955e-01,\n",
      "           -1.5493e-01, -1.5196e-01],\n",
      "          ...,\n",
      "          [-1.7278e-01, -2.1443e-01, -2.1740e-01,  ..., -2.5757e-01,\n",
      "           -1.5394e-01, -1.1130e-01],\n",
      "          [-1.8766e-01, -1.8964e-01, -2.1443e-01,  ..., -1.2232e-03,\n",
      "            2.8239e-01,  4.1329e-01],\n",
      "          [-1.7278e-01, -1.7278e-01, -2.2534e-01,  ..., -7.1731e-03,\n",
      "            2.6752e-01,  4.1329e-01]],\n",
      "\n",
      "         [[ 1.2901e-01,  2.9955e-01,  1.4213e-01,  ..., -7.2491e-01,\n",
      "           -5.0308e-01, -3.1823e-01],\n",
      "          [ 6.3414e-02,  5.6312e-01,  2.9836e-01,  ..., -7.3445e-01,\n",
      "           -5.2813e-01, -3.8024e-01],\n",
      "          [ 4.1947e-02,  5.3808e-01,  3.3295e-01,  ..., -7.5234e-01,\n",
      "           -6.3069e-01, -5.2574e-01],\n",
      "          ...,\n",
      "          [ 4.4386e-01,  4.7129e-01,  3.6515e-01,  ...,  2.2919e-01,\n",
      "            8.4881e-02,  1.5709e-02],\n",
      "          [ 4.9991e-01,  4.2359e-01,  3.1625e-01,  ...,  8.5532e-03,\n",
      "            6.1029e-02,  1.9699e-01],\n",
      "          [ 3.6038e-01,  3.3533e-01,  3.6395e-01,  ...,  7.4147e-02,\n",
      "            1.2304e-01,  1.9341e-01]]]]), 'clean': tensor([[[-0.1267, -0.4905, -0.2495,  ...,  0.1810,  0.1874,  0.1607],\n",
      "         [-0.0727, -0.4632, -0.4760,  ...,  0.0929,  0.1062,  0.1255],\n",
      "         [-0.1470, -0.4135, -0.3404,  ...,  0.0363,  0.0443,  0.0261],\n",
      "         ...,\n",
      "         [-0.3719, -0.4728, -0.4894,  ..., -0.3286, -0.2164, -0.0909],\n",
      "         [-0.4921, -0.4210, -0.5049,  ..., -0.0423,  0.0720,  0.2002],\n",
      "         [-0.4771, -0.4499, -0.4867,  ..., -0.2025, -0.0701,  0.2216]],\n",
      "\n",
      "        [[-0.3407, -0.4727, -0.3730,  ..., -0.1699, -0.1519, -0.1572],\n",
      "         [-0.3630, -0.4818, -0.4621,  ..., -0.1922, -0.1827, -0.1784],\n",
      "         [-0.3598, -0.4558, -0.4250,  ..., -0.2474, -0.2537, -0.2367],\n",
      "         ...,\n",
      "         [-0.4054, -0.4473, -0.4346,  ..., -0.3497, -0.3046, -0.1190],\n",
      "         [-0.4892, -0.4340, -0.4499,  ..., -0.1667, -0.0310,  0.1217],\n",
      "         [-0.4303, -0.4070, -0.4356,  ..., -0.2972, -0.2039,  0.0623]],\n",
      "\n",
      "        [[-0.4559, -0.5298, -0.4767,  ..., -0.2729, -0.2710, -0.2853],\n",
      "         [-0.4435, -0.5313, -0.5541,  ..., -0.3081, -0.3081, -0.3067],\n",
      "         [-0.4495, -0.5392, -0.4966,  ..., -0.3473, -0.3572, -0.3671],\n",
      "         ...,\n",
      "         [-0.4718, -0.5288, -0.5382,  ..., -0.4133, -0.2154, -0.0696],\n",
      "         [-0.5466, -0.5134, -0.5407,  ..., -0.2273,  0.0156,  0.2457],\n",
      "         [-0.5273, -0.5243, -0.5298,  ..., -0.3895, -0.3309,  0.0256]],\n",
      "\n",
      "        [[-0.2646,  0.4373,  0.3795,  ..., -0.3659, -0.3671, -0.3373],\n",
      "         [-0.3218,  0.1397,  0.5059,  ..., -0.4429, -0.4399, -0.4256],\n",
      "         [-0.2866,  0.0986,  0.3198,  ..., -0.4965, -0.5007, -0.4888],\n",
      "         ...,\n",
      "         [ 0.0879,  0.1672,  0.2012,  ..., -0.0570, -0.1435, -0.0547],\n",
      "         [ 0.1272,  0.0270,  0.0091,  ..., -0.2556, -0.1948, -0.0022],\n",
      "         [-0.0010, -0.0254, -0.0093,  ..., -0.2335,  0.1910, -0.0016]]])}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91a4438a62e1fec4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
