{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:16.575931Z",
     "start_time": "2025-11-20T04:25:12.529649Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchvision.transforms.v2.functional import normalize"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:16.588856Z",
     "start_time": "2025-11-20T04:25:16.575931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SatImage_Dataloader(Dataset):\n",
    "    \"\"\"\n",
    "    Mono-temporal Sen2-MTC dataset with patch extraction.\n",
    "\n",
    "    For each time index n:\n",
    "        cloudy[n] has multiple *.tif files\n",
    "        cloudless[n] has one  *.tif file\n",
    "\n",
    "    One cloudy sample for each n -> mono-temporal.\n",
    "    If patch_size is provided:\n",
    "        If center_crop True : return crop from the center of image.\n",
    "        If center_crop False: return a random crop on the image.\n",
    "\n",
    "    If stride is provided:\n",
    "        Enumerate all patches of size patch_size with given stride.\n",
    "        (This multiplies dataset size with deterministic patches.)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, route, patch_size=128, stride=128, center_crop=False, transform=None):\n",
    "        super().__init__()\n",
    "        self.root_dir = route\n",
    "        self.patch_size = patch_size\n",
    "        self.center_crop = center_crop\n",
    "        self.transform = transform\n",
    "        self.stride = stride  # NEW\n",
    "\n",
    "        # List of samples:\n",
    "        # If stride is None:       (cloudy_path, clean_path)\n",
    "        # If stride is not None:   (cloudy_path, clean_path, top, left)\n",
    "        self.samples = []\n",
    "\n",
    "        cloudy_pattern    = r\"(.+?)_(\\d+)_(\\d+)\\.tif\"       # matches n_k (cloud)\n",
    "        cloudless_pattern = r\"(.+?)_(\\d+)\\.tif\"            # matches n (clean)\n",
    "\n",
    "        for tile_name in sorted(os.listdir(route)):\n",
    "            tile_path = os.path.join(route, tile_name)\n",
    "            cloud_dir = os.path.join(tile_path, \"cloud\")\n",
    "            clean_dir = os.path.join(tile_path, \"cloudless\")\n",
    "\n",
    "            if not (os.path.isdir(cloud_dir) and os.path.isdir(clean_dir)):\n",
    "                continue\n",
    "\n",
    "            # 1 — Parse cloudy files grouped by time index n\n",
    "            cloudy_by_n = {}\n",
    "            for fname in sorted(os.listdir(cloud_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudy_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                path = os.path.join(cloud_dir, fname)\n",
    "                cloudy_by_n.setdefault(n, []).append(path)\n",
    "\n",
    "            # 2 — Parse cloudless (clean) files by time index n\n",
    "            clean_by_n = {}\n",
    "            for fname in sorted(os.listdir(clean_dir)):\n",
    "                if not fname.endswith(\".tif\"):\n",
    "                    continue\n",
    "                m = re.match(cloudless_pattern, fname)\n",
    "                if not m:\n",
    "                    continue\n",
    "\n",
    "                n = int(m.group(2))\n",
    "                clean_by_n[n] = os.path.join(clean_dir, fname)\n",
    "\n",
    "            # 3 — For each n, pick *one* cloudy and match with clean[n]\n",
    "            for n in sorted(cloudy_by_n.keys()):\n",
    "                if n not in clean_by_n:\n",
    "                    print(f\"[WARNING] Tile {tile_name}: time {n} has cloudy but no clean.\")\n",
    "                    continue\n",
    "\n",
    "                cloudy_path = cloudy_by_n[n][0]   # mono-temporal choose first\n",
    "                clean_path = clean_by_n[n]\n",
    "\n",
    "                # If stride is not provided → old behavior: 1 sample per image\n",
    "                if self.stride is None:\n",
    "                    self.samples.append((cloudy_path, clean_path, None, None))\n",
    "                    continue\n",
    "\n",
    "                # Otherwise enumerate patches using stride\n",
    "                # We must load image shape\n",
    "                tmp = tiff.imread(cloudy_path)  # (H, W, C)\n",
    "                H, W, _ = tmp.shape\n",
    "\n",
    "                ps = self.patch_size\n",
    "                st = self.stride\n",
    "\n",
    "                for top in range(0, H - ps + 1, st):\n",
    "                    for left in range(0, W - ps + 1, st):\n",
    "                        self.samples.append((cloudy_path, clean_path, top, left))\n",
    "\n",
    "        print(f\"[Sen2MTC loaded] Total samples (including patches): {len(self.samples)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def load_tif(self, path):\n",
    "        arr = tiff.imread(path)  # (H, W, C)\n",
    "        arr = np.array(arr, dtype=np.float32)\n",
    "        return arr\n",
    "\n",
    "    # Patch extraction helper\n",
    "    def extract_patch(self, img, size):\n",
    "        \"\"\"\n",
    "        img: numpy array shape (C,H,W)\n",
    "        size: int, patch size\n",
    "        returns: (C, size, size)\n",
    "        \"\"\"\n",
    "        _, H, W = img.shape\n",
    "        if size > H or size > W:\n",
    "            raise ValueError(f\"Patch size {size} > image size {(H,W)}\")\n",
    "\n",
    "        if self.center_crop:\n",
    "            top = (H - size) // 2\n",
    "            left = (W - size) // 2\n",
    "        else:\n",
    "            top = np.random.randint(0, H - size + 1)\n",
    "            left = np.random.randint(0, W - size + 1)\n",
    "\n",
    "        patch = img[:, top:top+size, left:left+size]\n",
    "        return patch\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cloudy_path, clean_path, top, left = self.samples[idx]\n",
    "\n",
    "        cloudy = self.load_tif(cloudy_path)\n",
    "        clean  = self.load_tif(clean_path)\n",
    "\n",
    "        cloudy = torch.from_numpy(cloudy.transpose(2,0,1))\n",
    "        clean  = torch.from_numpy(clean.transpose(2,0,1))\n",
    "\n",
    "        # Patch extraction\n",
    "        if self.patch_size is not None:\n",
    "            if self.stride is not None:\n",
    "                # predetermined patch from (top, left)\n",
    "                ps = self.patch_size\n",
    "                cloudy = cloudy[:, top:top+ps, left:left+ps]\n",
    "                clean  = clean[:, top:top+ps, left:left+ps]\n",
    "            else:\n",
    "                # center or random crop\n",
    "                cloudy = self.extract_patch(cloudy, self.patch_size)\n",
    "                clean  = self.extract_patch(clean, self.patch_size)\n",
    "\n",
    "        sample = {\n",
    "            \"cloudy\": cloudy,\n",
    "            \"clean\": clean,\n",
    "            \"cloudy_path\": cloudy_path,\n",
    "            \"clean_path\": clean_path\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n"
   ],
   "id": "d4e2c3dcc2f4d920",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:18.525264Z",
     "start_time": "2025-11-20T04:25:16.769542Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "route = './Sen2_MTC/dataset/Sen2_MTC'    # route to data\n",
    "size = 128              # if size = patch_size = stride -> no overlapping sampling\n",
    "batch_size = 16"
   ],
   "id": "9db1e26fbe116d7b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:18.542948Z",
     "start_time": "2025-11-20T04:25:18.537900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compute_global_stats(dataset, batch_size=32):\n",
    "    \"\"\"\n",
    "    Compute global per-channel mean and std over a dataset.\n",
    "    Returns:\n",
    "        mean, std\n",
    "    \"\"\"\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    channel_sum = None\n",
    "    channel_sq_sum = None\n",
    "    total_pixels = 0\n",
    "\n",
    "    for batch in loader:\n",
    "        x = batch[\"cloudy\"].double()   # (B,C,H,W)\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        if channel_sum is None:\n",
    "            channel_sum = torch.zeros(C, dtype=torch.float64)\n",
    "            channel_sq_sum = torch.zeros(C, dtype=torch.float64)\n",
    "\n",
    "        # Sum over batch and spatial dims\n",
    "        channel_sum += x.sum(dim=[0, 2, 3])\n",
    "        channel_sq_sum += (x ** 2).sum(dim=[0, 2, 3])\n",
    "\n",
    "        total_pixels += B * H * W\n",
    "\n",
    "    mean = channel_sum / total_pixels\n",
    "    std = torch.sqrt(channel_sq_sum / total_pixels - mean**2)\n",
    "\n",
    "    print(\"Global mean:\", mean)\n",
    "    print(\"Global std:\", std)\n",
    "\n",
    "    return mean.float(), std.float()"
   ],
   "id": "2c003bd5cc495c50",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:18.556706Z",
     "start_time": "2025-11-20T04:25:18.553171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Normalization:\n",
    "    \"\"\"\n",
    "    Normalize cloudy and clean patches using precomputed mean/std.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean.reshape(-1, 1, 1)   # (C,1,1)\n",
    "        self.std  = std.reshape(-1, 1, 1)    # (C,1,1)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        cloudy = sample[\"cloudy\"]\n",
    "        clean  = sample[\"clean\"]\n",
    "\n",
    "        cloudy_n = (cloudy - self.mean) / (self.std + 1e-6)\n",
    "        clean_n  = (clean  - self.mean) / (self.std + 1e-6)\n",
    "\n",
    "        return {\n",
    "            \"cloudy\": cloudy_n,\n",
    "            \"clean\": clean_n,\n",
    "            \"cloudy_path\": sample[\"cloudy_path\"],\n",
    "            \"clean_path\": sample[\"clean_path\"],\n",
    "        }"
   ],
   "id": "5a5c575620230fb1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:58.995575Z",
     "start_time": "2025-11-20T04:25:18.561014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset_raw = SatImage_Dataloader(route=route, patch_size=size, stride=size)\n",
    "mean, std = compute_global_stats(dataset_raw, batch_size=batch_size)\n",
    "normalized = Normalization(mean, std)\n",
    "\n",
    "dataset = SatImage_Dataloader(route=route, patch_size=size, stride=size, transform=normalized)\n",
    "train_ratio=.7; val_ratio=.15; test_ratio=.15\n",
    "\n",
    "total       = len(dataset)\n",
    "train_len   = int(train_ratio*total)\n",
    "val_len     = int(val_ratio*total)+1\n",
    "test_len    = int(test_ratio*total)\n",
    "\n",
    "generator = torch.Generator().manual_seed(2025)\n",
    "train_set, val_set, test_set = random_split(dataset, \n",
    "                                            [train_len, val_len, test_len],\n",
    "                                            generator=generator) #reproducability\n",
    "\n",
    "train_loader    = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_loader      = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "test_loader     = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)"
   ],
   "id": "6a5bb777a2496a21",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sen2MTC loaded] Total samples (including patches): 13668\n",
      "Global mean: tensor([1993.3346, 2019.7630, 1915.7268, 3308.8526], dtype=torch.float64)\n",
      "Global std: tensor([1963.2201, 1986.5921, 2124.9866, 1794.3806], dtype=torch.float64)\n",
      "[Sen2MTC loaded] Total samples (including patches): 13668\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:59.132980Z",
     "start_time": "2025-11-20T04:25:59.005956Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for batch in train_loader:\n",
    "    print(batch['cloudy'].shape)\n",
    "    print(batch['clean'].shape)\n",
    "    x = batch['cloudy']\n",
    "    print(x.mean(), x.std())\n",
    "    break\n",
    "#[batch_size, channels, height, width] -> [batch_size, channels, patch_size, patch_size]"
   ],
   "id": "f8f170bbc63a342",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4, 128, 128])\n",
      "torch.Size([16, 4, 128, 128])\n",
      "tensor(-0.2416) tensor(0.7219)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ac42d10a1c854104"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:25:59.221161Z",
     "start_time": "2025-11-20T04:25:59.218050Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1d656281ba1a4050",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
